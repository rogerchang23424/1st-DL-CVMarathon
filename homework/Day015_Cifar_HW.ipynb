{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test, mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rogerchang\\anaconda3\\envs\\tf-gpu2.0\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=500)`\n",
      "c:\\users\\rogerchang\\anaconda3\\envs\\tf-gpu2.0\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=500)`\n",
      "c:\\users\\rogerchang\\anaconda3\\envs\\tf-gpu2.0\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "c:\\users\\rogerchang\\anaconda3\\envs\\tf-gpu2.0\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 1.5881 - accuracy: 0.4086 - val_loss: 1.3720 - val_accuracy: 0.5276\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 1.0782 - accuracy: 0.6265 - val_loss: 1.1924 - val_accuracy: 0.5958\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.8828 - accuracy: 0.7020 - val_loss: 0.8603 - val_accuracy: 0.7081\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 0.7567 - accuracy: 0.7454 - val_loss: 0.8158 - val_accuracy: 0.7218\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.6702 - accuracy: 0.7779 - val_loss: 0.9161 - val_accuracy: 0.6954\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 18s 366us/step - loss: 0.6030 - accuracy: 0.8012 - val_loss: 0.7966 - val_accuracy: 0.7433\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 0.5474 - accuracy: 0.8212 - val_loss: 0.7588 - val_accuracy: 0.7560\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 0.4980 - accuracy: 0.8366 - val_loss: 0.6328 - val_accuracy: 0.7953\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 0.4512 - accuracy: 0.8509 - val_loss: 0.6703 - val_accuracy: 0.7771\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 0.4161 - accuracy: 0.8633 - val_loss: 0.5706 - val_accuracy: 0.8164\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 0.3838 - accuracy: 0.8757 - val_loss: 0.6030 - val_accuracy: 0.8062\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 0.3508 - accuracy: 0.8841 - val_loss: 0.6031 - val_accuracy: 0.8123\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.3233 - accuracy: 0.8937 - val_loss: 0.6776 - val_accuracy: 0.7997\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.2986 - accuracy: 0.9023 - val_loss: 0.8386 - val_accuracy: 0.7624\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 0.2771 - accuracy: 0.9084 - val_loss: 0.6404 - val_accuracy: 0.8074\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 0.2597 - accuracy: 0.9151 - val_loss: 0.6145 - val_accuracy: 0.8218\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.2410 - accuracy: 0.9221 - val_loss: 0.8057 - val_accuracy: 0.7742\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.2195 - accuracy: 0.9285 - val_loss: 0.6219 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.2087 - accuracy: 0.9315 - val_loss: 0.6744 - val_accuracy: 0.8169\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 19s 370us/step - loss: 0.1963 - accuracy: 0.9363 - val_loss: 0.6416 - val_accuracy: 0.8217\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 0.1868 - accuracy: 0.9400 - val_loss: 0.6307 - val_accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 0.1735 - accuracy: 0.9438 - val_loss: 0.6457 - val_accuracy: 0.8265\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.1672 - accuracy: 0.9462 - val_loss: 0.7400 - val_accuracy: 0.8217\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.1616 - accuracy: 0.9474 - val_loss: 0.6429 - val_accuracy: 0.8341\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 0.1483 - accuracy: 0.9517 - val_loss: 0.8448 - val_accuracy: 0.7961\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1461 - accuracy: 0.9525 - val_loss: 0.7757 - val_accuracy: 0.8081\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 0.1322 - accuracy: 0.9572 - val_loss: 0.8017 - val_accuracy: 0.8117\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 0.1327 - accuracy: 0.9575 - val_loss: 0.7481 - val_accuracy: 0.8206\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.1279 - accuracy: 0.9586 - val_loss: 0.7653 - val_accuracy: 0.8233\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1140 - accuracy: 0.9637 - val_loss: 0.7820 - val_accuracy: 0.8279\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.1166 - accuracy: 0.9633 - val_loss: 0.8410 - val_accuracy: 0.8191\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 18s 360us/step - loss: 0.1092 - accuracy: 0.9655 - val_loss: 0.8220 - val_accuracy: 0.8288\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.1144 - accuracy: 0.9641 - val_loss: 0.7527 - val_accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 18s 367us/step - loss: 0.1053 - accuracy: 0.9674 - val_loss: 0.8872 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1043 - accuracy: 0.9672 - val_loss: 0.7800 - val_accuracy: 0.8240\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.0976 - accuracy: 0.9692 - val_loss: 0.8172 - val_accuracy: 0.8211\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 0.0972 - accuracy: 0.9692 - val_loss: 0.8997 - val_accuracy: 0.8173\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.0948 - accuracy: 0.9712 - val_loss: 0.8740 - val_accuracy: 0.8226\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 0.9256 - val_accuracy: 0.8172\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.0839 - accuracy: 0.9742 - val_loss: 0.8771 - val_accuracy: 0.8291\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 0.0904 - accuracy: 0.9730 - val_loss: 0.8293 - val_accuracy: 0.8293\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.0885 - accuracy: 0.9730 - val_loss: 0.8360 - val_accuracy: 0.8196\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.0804 - accuracy: 0.9751 - val_loss: 1.0063 - val_accuracy: 0.8031\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.0847 - accuracy: 0.9735 - val_loss: 0.8920 - val_accuracy: 0.8222\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 0.0753 - accuracy: 0.9765 - val_loss: 0.8716 - val_accuracy: 0.8219\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.8695 - val_accuracy: 0.8227\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 0.0816 - accuracy: 0.9749 - val_loss: 0.8113 - val_accuracy: 0.8310\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.0808 - accuracy: 0.9759 - val_loss: 0.9662 - val_accuracy: 0.8149\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.9131 - val_accuracy: 0.8273\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.0724 - accuracy: 0.9784 - val_loss: 0.8505 - val_accuracy: 0.8301\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.9016 - val_accuracy: 0.8300\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.0701 - accuracy: 0.9800 - val_loss: 0.9907 - val_accuracy: 0.8152\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 0.0684 - accuracy: 0.9796 - val_loss: 0.8565 - val_accuracy: 0.8292\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 18s 370us/step - loss: 0.0702 - accuracy: 0.9793 - val_loss: 0.8770 - val_accuracy: 0.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.0669 - accuracy: 0.9804 - val_loss: 0.9072 - val_accuracy: 0.8292\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.0653 - accuracy: 0.9817 - val_loss: 1.0101 - val_accuracy: 0.8174\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.0708 - accuracy: 0.9795 - val_loss: 0.8690 - val_accuracy: 0.8302\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.9250 - val_accuracy: 0.8266\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.0672 - accuracy: 0.9803 - val_loss: 0.9292 - val_accuracy: 0.8259\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.0618 - accuracy: 0.9817 - val_loss: 0.9089 - val_accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 0.0694 - accuracy: 0.9794 - val_loss: 0.9680 - val_accuracy: 0.8288\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.0577 - accuracy: 0.9830 - val_loss: 0.8971 - val_accuracy: 0.8328\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 1.0182 - val_accuracy: 0.8200\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.0591 - accuracy: 0.9827 - val_loss: 0.9571 - val_accuracy: 0.8250\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 0.0586 - accuracy: 0.9831 - val_loss: 0.9820 - val_accuracy: 0.8252\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 18s 359us/step - loss: 0.0579 - accuracy: 0.9834 - val_loss: 0.9372 - val_accuracy: 0.8302\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.9898 - val_accuracy: 0.8297\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 18s 368us/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.8668 - val_accuracy: 0.8341\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 17s 345us/step - loss: 0.0603 - accuracy: 0.9826 - val_loss: 0.8419 - val_accuracy: 0.8356\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 0.0592 - accuracy: 0.9835 - val_loss: 0.9276 - val_accuracy: 0.8244\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.9076 - val_accuracy: 0.8229\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 1.0031 - val_accuracy: 0.8295\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 0.0535 - accuracy: 0.9844 - val_loss: 1.0029 - val_accuracy: 0.8282\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 1.0245 - val_accuracy: 0.8179\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 18s 361us/step - loss: 0.0491 - accuracy: 0.9857 - val_loss: 1.0426 - val_accuracy: 0.8224\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 0.0525 - accuracy: 0.9850 - val_loss: 1.0870 - val_accuracy: 0.8323\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 0.0536 - accuracy: 0.9851 - val_loss: 0.9545 - val_accuracy: 0.8311\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 18s 366us/step - loss: 0.0558 - accuracy: 0.9845 - val_loss: 0.9106 - val_accuracy: 0.8367\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.0493 - accuracy: 0.9858 - val_loss: 1.0025 - val_accuracy: 0.8297\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 0.9553 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 0.0446 - accuracy: 0.9871 - val_loss: 0.9956 - val_accuracy: 0.8327\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.0512 - accuracy: 0.9856 - val_loss: 0.9346 - val_accuracy: 0.8252\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 1.1108 - val_accuracy: 0.8199\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 0.9845 - val_accuracy: 0.8269\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.0484 - accuracy: 0.9863 - val_loss: 0.9495 - val_accuracy: 0.8318\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 0.9578 - val_accuracy: 0.8341\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 17s 345us/step - loss: 0.0499 - accuracy: 0.9862 - val_loss: 0.9397 - val_accuracy: 0.8376\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.0463 - accuracy: 0.9863 - val_loss: 0.9938 - val_accuracy: 0.8218\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.9472 - val_accuracy: 0.8307\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 0.0487 - accuracy: 0.9865 - val_loss: 1.0110 - val_accuracy: 0.8316\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.0445 - accuracy: 0.9874 - val_loss: 1.0138 - val_accuracy: 0.8353\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 1.0279 - val_accuracy: 0.8363\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 0.0404 - accuracy: 0.9888 - val_loss: 1.0759 - val_accuracy: 0.8253\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 0.0440 - accuracy: 0.9879 - val_loss: 1.1906 - val_accuracy: 0.8184\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.0428 - accuracy: 0.9885 - val_loss: 1.0670 - val_accuracy: 0.8348\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 1.0589 - val_accuracy: 0.8293\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 19s 371us/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.9952 - val_accuracy: 0.8381\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 1.0550 - val_accuracy: 0.8338\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 1.1698 - val_accuracy: 0.8250\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 1.1318 - val_accuracy: 0.8289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22c2b158dc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3,3), input_shape=(32,32,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Convolution2D(32, kernel_size=(3,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=500, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(output_dim=500, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(output_dim=100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer='adam', loss ='categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('images/test2.png')\n",
    "img_array = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22c32e57708>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 7.6818439e-24, 3.6068860e-37, 8.7508918e-29,\n",
       "        1.6245432e-28, 9.2835239e-37, 0.0000000e+00, 7.1342189e-34,\n",
       "        4.0245222e-38, 1.3703030e-32]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(img_array-mean_train)/(std_train+1e-7)\n",
    "\n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
